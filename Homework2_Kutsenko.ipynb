{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kfi9Hc6YbzC9"
   },
   "source": [
    "# Домашнее задание №2: линейная регрессия (10 баллов).\n",
    "\n",
    "Некоторые задания будут по вариантам (всего 4 варианта). Чтобы выяснить свой вариант, посчитайте количество букв в своей фамилии, возьмете остаток от деления на 4 и прибавьте 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHGE7dRHb59T"
   },
   "source": [
    "Антон Куценко $\\rightarrow$ Вариант 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "42QIkzv7bzDB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PphjvLz6bzDS"
   },
   "source": [
    "## Многомерная линейная регрессия из sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GuM7c9ofbzDU"
   },
   "source": [
    "Применим многомерную регрессию из sklearn для стандартного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "xPgd3yShbzDW",
    "outputId": "d11f9e2c-3128-4bab-de23-be82cc2a6d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100) (10000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples = 10000, random_state=42)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5uN9e3aTbzDk"
   },
   "source": [
    "У нас 10000 объектов и 100 признаков. Для начала решим задачу аналитически \"из коробки\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "a-Gzf1_EbzDm",
    "outputId": "a7e3fdf9-b50c-436a-98e8-98699637f1db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.587185251360931e-25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "regr = LinearRegression().fit(X, y)\n",
    "osh1 = mean_squared_error(y, regr.predict(X))\n",
    "print(mean_squared_error(y, regr.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3pO8atDbzDw"
   },
   "source": [
    "Теперь попробуем обучить линейную регрессию методом градиентного спуска \"из коробки\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 468
    },
    "id": "zaeBpvZIbzDy",
    "outputId": "e30b580f-b916-4b4d-c281-0d9e50ded9a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.965356354236384e-12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3.75597023e-08,  6.37672897e-08, -5.59948943e-09, -3.71940829e-08,\n",
       "        2.46961389e-08,  5.56172488e-09, -2.37290157e-08, -4.35955159e-08,\n",
       "        5.68645675e-08, -5.43009511e-08, -3.80308880e-08,  3.26829624e+01,\n",
       "       -3.46018473e-08,  2.45759783e-08,  4.62802021e-08,  1.33913762e-08,\n",
       "       -5.93085182e-08, -1.12283768e-08,  3.55644170e-08, -4.54512235e-09,\n",
       "        6.67389281e-08,  2.40776950e-09,  2.45548500e-08,  8.26861720e+01,\n",
       "        2.80816212e-09, -6.96115103e-08, -3.40415543e-09, -4.63311618e-08,\n",
       "       -1.02613836e-08, -3.51511937e-08, -8.36638661e-09, -7.38338135e-08,\n",
       "       -4.64945056e-08, -8.30548221e-08, -3.01523744e-08, -8.37011520e-08,\n",
       "       -4.27278656e-08, -3.81510428e-09,  4.45438322e-08,  1.91317508e-08,\n",
       "        2.12696059e-08,  3.21576448e-08, -2.72703418e-08,  3.00707399e-08,\n",
       "        1.22432338e-08,  1.72568045e-08,  5.60394311e+01,  6.32578883e+01,\n",
       "        1.69423525e-08, -5.28528778e-08, -1.28248535e-08,  1.75466249e-08,\n",
       "        9.01726066e+01, -1.61406480e-08,  4.75412378e-08, -4.23472151e-08,\n",
       "        4.68463932e-08,  2.05715137e+01,  7.15561931e+01, -5.74940486e-09,\n",
       "        3.69290093e-08,  1.16655395e-08, -1.09233021e-08,  2.42999962e-08,\n",
       "       -1.29588938e-08, -3.80374571e-08,  4.69651887e-08,  2.11466249e+01,\n",
       "        8.99420622e-09, -4.47121565e-08,  2.57264951e-09, -2.70140211e-08,\n",
       "       -1.14427871e-08, -5.89974182e-08, -2.44492379e-08,  5.43206038e-09,\n",
       "       -1.45693430e-08, -8.08865437e-09,  7.65136898e-08,  4.19168127e-08,\n",
       "        3.28059787e-08, -1.38004306e-08,  5.84533353e-08, -4.98058583e-08,\n",
       "        9.55554868e-09,  7.43906731e-08,  6.97006910e-09, -5.11845112e-08,\n",
       "        4.02144311e+01, -1.35133815e-08,  4.84352542e-08,  1.36007992e-08,\n",
       "        3.62933132e-08,  1.39018376e-08,  8.49118205e+01,  6.87400991e-09,\n",
       "       -7.35306863e-08,  2.80980322e-08,  7.18569214e-09,  2.52580315e-08])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "reg = SGDRegressor(alpha=0.00000001).fit(X, y)\n",
    "osh2 = mean_squared_error(y, reg.predict(X))\n",
    "print(mean_squared_error(y, reg.predict(X)))\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QcBYWvP23KV"
   },
   "source": [
    "##Задание 1 (1 балл)\n",
    " Объясните, чем вызвана разница в значениях двух полученных значений метрики?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-H1Enn9tHp-"
   },
   "source": [
    "Причиной расхождения в значениях MSE стало внутреннее устройство алгоритма, стохастический градиентный спуск имеет параметр шага градиента, который может повлиять на сходимость возле минимума. В то же самое время линейная регрессия из sklearn использует аналитическое решение с обращением матриц. Если количество объектов в наших данных было бы в разы больше( например, 1млн объектов и 100 признаков), то разница во времени обучения была бы уже значительной, при этом качество, конечно, лучше в случае аналитического решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AmDgSUwf6Vtb"
   },
   "source": [
    "##Задание 2 (1 балл)\n",
    "Подберите гиперпараметры в методе градиентного спуска так, чтобы значение MSE было близко к значению MSE, полученному при обучении LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "yy7OAUKAdQMn",
    "outputId": "c2ac03bf-7a92-47fd-ddd2-60637f791607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальная MSE при использовании SGD :9.15459145555654e-25\n",
      "Подходящий learning rate: 1.0000000000000014e-25\n",
      "Разница MSE LinearRegression и SGD : 6.56740620419561e-25\n"
     ]
    }
   ],
   "source": [
    "a = np.linspace(0.00000001, 0.1**25, num = 100) # массив вариантов learning rate\n",
    "error = osh2 # первоначальная MSE при learning rate = 0.00000001\n",
    "razn = osh2 - osh1 # первоначальная разница MSE \n",
    "for i in a:\n",
    "  reg = SGDRegressor(alpha=i).fit(X, y)\n",
    "  k = mean_squared_error(y, reg.predict(X))\n",
    "  if k  < error:\n",
    "    error, alp = k, i\n",
    "razn  = error - osh1  \n",
    "print(\"Минимальная MSE при использовании SGD :{}\".format(error))\n",
    "print(\"Подходящий learning rate: {}\".format(alp))\n",
    "print(\"Разница MSE LinearRegression и SGD : {}\".format(razn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3P0yF-SpbzEC"
   },
   "source": [
    "## Ваша многомерная линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7iH1VaUrsEz"
   },
   "source": [
    "##Задание 3 (5 баллов)\n",
    "Напишите собственную многомерную линейную регрессию, оптимизирующую MSE методом *градиентного спуска*. Для этого используйте шаблонный класс. \n",
    "\n",
    "Критерий останова: либо норма разности весов на текущей и предыдущей итерациях меньше определенного значения (первый и третий варианты), либо модуль разности функционалов качества (MSE) на текущей и предыдущей итерациях меньше определенного значения (второй и четвертый варианты). Также предлагается завершать обучение в любом случае, если было произведено слишком много итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "1Ze0729dqaEK"
   },
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self, alpha=0.485, l_ratio=0.000001, tol=0.1**5, max_iter=1000):\n",
    "        '''\n",
    "        Для начала необходимо инициализировать параметры\n",
    "        alpha - это learning rate или шаг обучения\n",
    "        l_ratio - параметр регуляризации\n",
    "        tol - значение для критерия останова\n",
    "        max_iter - максимальное количество итераций обучения\n",
    "        '''\n",
    "        self.max_iter = max_iter\n",
    "        self.tol= tol\n",
    "        self.l_ratio = l_ratio\n",
    "        self.alpha = alpha\n",
    "             \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Метод для обучения линейной регрессии\n",
    "        X - матрица признаков\n",
    "        y - вектор правильных ответов\n",
    "        '''\n",
    "        X = np.column_stack([np.array(X), [1]* X.shape[0]]) #добавим сразу признак, заданный единицами, чтоб не считать два градиента\n",
    "        y = np.array(y)\n",
    "        w = np.array([0]* (X.shape[1]))\n",
    "        n = len(y)\n",
    "        for i in range(self.max_iter):\n",
    "          y_current = np.matmul(X,w) \n",
    "          cost1 = (1/n) * sum((y - y_current)**2) \n",
    "          w_gradient = (2/n) * (-np.matmul(np.transpose(X), y) + np.matmul(np.matmul(np.transpose(X), X), w)) \n",
    "          w = w - self.alpha * w_gradient\n",
    "          y_current = np.matmul(X,w)\n",
    "          cost2 = (1/n) * sum((y - y_current)**2) \n",
    "          if cost1 - cost2 <= self.tol:\n",
    "            break\n",
    "        self.w = w\n",
    "\n",
    "        return w, cost2 \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Метод для предсказаний линейной регрессии\n",
    "        X - матрица признаков\n",
    "        '''\n",
    "        X = np.column_stack([np.array(X), [1]* X.shape[0]])\n",
    "        y_pred = np.matmul(X, self.w)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "4MCr3_ylrXIh",
    "outputId": "767b2544-c296-4103-a182-14885cec47cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.4082186853954137e-22\n",
      "You are amazing! Great work!\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples = 10000, random_state=42)\n",
    "my_reg = LinearRegression(tol=0.1**20) #изменяя значение для критерия останова, мы улучшаем качество, но тереям время\n",
    "my_reg.fit(X, y)\n",
    "print('MSE:',mean_squared_error(y, my_reg.predict(X)))\n",
    "assert mean_squared_error(y, my_reg.predict(X)) < 1e-3\n",
    "print('You are amazing! Great work!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "ZlgclcTRqXJb",
    "outputId": "e22be791-0009-4fff-ed83-3bdaf17cc010"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO29e5hUV53v/fl1dQHVJKFByYXmlokRDAG6EwQUopKLyUxi0hoVc/RMZkZPZubVV5NxGEFzDBnjiC+vJjPO7fEd53XmeCOa2OZ6MDE4GnKFdHcICdFouDVoSKBzgQaqq9f5Y9cudlfvtfeuql1Vu7p/n+fhoWtX1a616/Jda/2uYoxBURRFGVs01XsAiqIoSu1R8VcURRmDqPgriqKMQVT8FUVRxiAq/oqiKGMQFX9FUZQxiIq/MioQkf8mItNFZJKI/I96j0dRko6KvxILIvInIpITkTfy/46KyMM1HMIx4FHgeWBcDV9XURoSFX8lTh41xpxkjDkJ+ItavrAx5g5jzAxjzOnGmH+q5WsrSiOi4q/ERRrI2e4UkZ0icnH+75NE5PfenYGIGBF5i+f2LSLybc/tpSLyiIj0i0iviLzHc9/PReQT+b+bRGSbiOz1e+387U+IyM89t/9eRPaIyGsislVELvDc1yIit4vIwfyO5rh3XEXX+CcisllEviEir4rIDhG5yHP/JBH5lojsF5G+/DWmPM/17pzeEJErPO/Np0XktyLysoisF5Emz3n/TESeE5FDIrJRRGZ57psnIg/kx/97Efl8/nhKRD4vIr8Rkdfz1z2j+LMQkZkiMiAi3/Gc889FZFd+jIdFRMsENCAq/kpcZHBML1FYBWSjnlhE2oB7gVuAKcBfA3eIyFSfh18LTI567jxPAu35c38P+KGITMjf98fAHODM/I7m/wk51xLgt8CbgZuAO0VkSv6+/wAGgbcAHcB7gU94nlvYOeX/3eO57/3AIuA84CrgzwBEpBP4PPABYCrwS+D7+ftOBh4E/jcwLf+6P8uf76+Aa4A/Ak7Jn++Iz/V8CXjFvSEiE4F/Bq7Nvx8LQ94PJaGo+CtxMQU4FPYgETkN+Djw9RLO/THgPmPMfcaYIWPMA8AWHOHynnsC8D9xBCsyxpjvGGNeMcYMGmO+BozHEXwAyf9LRTzdS8BtxpisMWYDjg/i8vx1/yFwvTHmsDHmJeBW4CMRz/tVY8xBY8xu4DYc4Qb4c+ArxpjnjDGDwN8B7fnV/xXA74wxXzPGHDXGvG6MeTz/vE8ANxpjnjcOvcaYV7wvKCILgHfgTFouTcAQ0Bxx3EpC0Q9QiYszgd0RHrcW+AZw0Oe+p0RkKP/3BOAH+b9nAR8Skfd5HpsGNhU9/zPARhzBLaZLRAbzf48DnnDvEJHP4ojhNMDgrITfnL/7P3BW3AdE5A2cicEdlx99Zni1xF35887Kj3m/iLj3NQF7As7lxfs495zkz/v3IvI1z/0CtAEzgN9Yzhd0n8tXcSbTt7kHjDGvi8jHgf8UkVacnYzSgOjKX6mYvP35nTir8SDeClwK/IPl/vOMMa3GmFbg//Uc3wP8L/e+/L+Jxph1nsdMAT4F3Gw5d6fn3J/2jP0C4HPAh4HJ+ftfxRFQjDFHgHuAZ4A3FY3LjzbxqDswE9iXv4ZjwJs913CKMWZeyPlcZvick/x5/7zovckYYx7J33eW5XxB9wFciDMB3u5z349xzHYrcMxQSgOi4q9UhIi8CfhHYCKOXT6IG4G/NcYMlPgy3wHeJyKX5h2VE0TkPSIy3fOY64FvGWN+V+K5T8ZZvR4AmkXkizgrf8Bx0uJMVv8jb1YJ41Tg0yKSFpEP4aya7zPG7Ad+CnxNRE7JO6bPEpF3RxznKhGZnHfKfgbYkD/+r8AaEZnnjjf/uuBMWqeLyPUiMl5EThaRJfn7/g34koicLQ4L8p+ly1pgVdEuxuWrwF0eE5LSgKj4K5XyFzir0hXGmDdCHvsK8J+lvoAxZg+Ok/PzOCK9B8dp7P3+pghflfuxEbgf+BWOOeUow00s64E7jTFP+DzXj8eBs4GXgS8DH/TY0v8Yx+T0LI5/5EfAGRHP+xNgK9CDM8l+C8AY82McMf6BiLyGs0P5w/x9rwOXAO8Dfgf8Gme1Do7P5XacCem1/PkyntfrNsb8vHgQIrIMuBzns1AaGNFmLooSDyLyJ8AnjDHLYz6vAc42xrwQ53mVsY2u/BVFUcYgKv6KoihjEDX7KIqijEF05a8oijIGaZgkrze/+c1m9uzZ9R6GoihKQ7F169aXjTEjSqE0jPjPnj2bLVvCcogURVEULyKyy++4mn0URVHGICr+iqIoYxAVf0VRlDGIir+iKMoYRMVfURRlDNIw0T6KMpbo6u5j/cbn2dc/wLTWDKsunUNnR1u9h6WMIlT8FSVhdHX3sebObQxknZbIff0DrLlzG4BOAEpsqNlHURLG+o3PF4TfZSCbY/1GvwZlilIeKv6KkjD29fv3urEdV5RyUPFXlIQxrTVT0nFFKQcVf0VJGKsunUMmnRpx/PCxQbq6++owImU0og5fRUkYrlP35ru3c+hItnC8fyCrjl8lNnTlrygJpLOjjZZxI9dm6vhV4kLFX1ESijp+lWqi4q8oCUUdv0o1UfFXlITi5/jNpFOsunROnUYUL13dfSxb9xBnrr6XZeseUmd2jVGHr6IkFNepOxrLPGgWc/1R8VeUBNPZ0TYqxTAoi3k0Xm8SUbOPoig1R53Z9UfFX1GUmqPO7Pqj4q8oSs0Z7c7sRkBt/orSoDRyzf/R7MxuFFT8FaUBGQ3RMqPVmd0oqPgriaWRV7bVRqNllEqJTfxFJAVsAfqMMVeIyBRgAzAb2Al82BhzKP/YNcDHgRzwaWPMxrjGoYwORsPKtppUI1om6mSrk/LoIE6H72eA5zy3VwM/M8acDfwsfxsROQf4CDAPuAz45/zEoSgFtJtVMHFHy7iTbV//AIYTk21x1m3UxynJJxbxF5HpwOXAv3kOXwX8R/7v/wA6Pcd/YIw5Zox5EXgBWBzHOJTRg8aBBxN3tEzUyVYn5dFDXGaf24C/AU72HDvNGLMfwBizX0ROzR9vAx7zPG5v/piiFJjWmqHPR+jHYhx4kJklLvNL1MlWJ+XRQ8XiLyJXAC8ZY7aKyHuiPMXnmLGc+zrgOoCZM2eWPUal8Vh16ZxhNn8Ym3HgYb6PuGztUSdbnZRHD3GYfZYBV4rITuAHwIUi8h3g9yJyBkD+/5fyj98LzPA8fzqwz+/ExphvGmMWGWMWTZ06NYahKo1CZ0cbX/nAfNpaMwjQ1prhKx+Yz5ZdBzlrzX3MXn0vZ625jxu7ttV7qFWlVmaWqGYkbTE5eqh45W+MWQOsAciv/P/aGPMxEVkPXAusy///k/xT7gK+JyJfB6YBZwNPVDoOZfRRvLK9sWsb33lsd+F2zpjC7Vs659d8fLWgVmaWqGYkbTE5eqhmeYd1wCUi8mvgkvxtjDHbgduBZ4H/DXzSGJOznkVR8nz/8T0lHR8N1LIGTmdHG5tXX8itK9sBuGFDj2+d/UZrMal9A/yJNcnLGPNz4Of5v18BLrI87svAl+N8bWX0kzO+riHr8dFArX0fUfMrGsXxq/kidrSwm9IwpMQvVsB+vFEIWpnafB+dHW1VWdFG9TE0SlVODU21o+UdlIbhmiUzhtn8vcddGi37NMrK1C+qp1or2qgr+kaJxmqUHUo90JW/0jDc0jmfjy2dWVjpp0T42NKZBWdvI2aflrsytT1v7V3bKxpP1BV90I4kSTTKDqUe6MpfaShu6ZxvjexplGJn3t2JzVvhrkxtOxnbyrV/IEtXd1/Z11vKij5KnkG9d2KNskOpByr+yqihEbb4xeYaG9NaM76mnRs29HD9hh5SIlZH92dv7wXKM//EmTmcBGer9g2wo+KvjBqSlH1qW/H67U6KcVemfo915T4owilnTEUiG1fmcFJ2Yto3wB+1+SujhqS0Buzq7mPVj3qH+R5W/aiXru6+0F2I13ZeyY4lCREtfhNx0HGltqj4K6OGpDghb757O9nc8JV5Nme4+e7tgbsQ70S1bN1DVn9AVOpt7hqtobmjBTX7KKOKJGzxvWUPio/f9L55Vpv/QDbHX93ew1BMOWv1jmgZi0l5jYSKv6LUEHdiun5Dj+/9QcIvWMrf+hC3uaucqJ02iw+mTcMsE4GafZSaM9prrbRm0oHHOzvayhLAW1e2DzNpTW7xf52USKzmrnLzJ6L4YEb7dyHJqPgrNaURE7FKZe2V80g3Dbdrp5uEtVfOK9y2lUa2IcCWXQeHHbt8wRm+4vq1Dy/0zQguV2TLTUQL88Ek6bswFichNfsoNSUp4X/VpLOjjS27DvL9x/eQM4aUCCsXzxh2fcXx500BcfvgmHu++9jugtmnr3+AO7b2cfX5bWzacSDQHFNpvH0l+RNBPpikfBeSkI9gG1c18xNU/JWa0giJWJXS1d3HHVv7CmKeM4Y7tvaxaNaUERNA8So4KAegeGoYyObYtOMAm1dfGDieSkW2WvkTSfkuJGUS8lKLCUnNPkpNGQu1Vsoxk3hNJKUQRShtcfVRRbaU/IlSzCdJ+S4kZRLyUotqpCr+Sk1JSiJWNbGJRl//wAhB9Irl+o3Ps+rSOdy2sj2yPyBMKLu6+3ybZnufGybYUfMnSrXhJ+W7kJRJyEstJiQ1+yg1xVZrBZzEptFQf6W1JW2N9fdu37fsOjjCjn/Dhh4MMHFcuPhHEcr1G5/3DQ8VHPGNal6Ikj9RqvkkKXV3klj8rRalSlT8lZpTLCRJdbiVQ1d3H/0D/sLv4pZefnUgO0KY3duHj/vb/lMiDBkTWShtK0WD894uW/dQbPbuclarSUjKS8ok5KUWE5KKv1J3qulwizNiIuxc7iQWJYE1bIKwMWQML667PPLjbStI17cQp3khSYX1SiUJk5CXWkxIKv5K3alEgIoFecXcqYXQx9aWNG8cHSSbT5st3lG4z+3rHyiUSG6ziPrNd28fZsrx253cfPf20IqdldIkUrCh267bKxRhK8g4BTuJ5pNGptoTkoq/UnfKFSA/c5G3zaOf3d0bMeF9rhuW6drdt+w6yC2d8wNDML27k67uPqudv5hMOsWEdFPkx3vJGcOqH/aCUCgeV3zdfhOTbQUZp2An0Xyi2BHTIEWWFi1aZLZs2VLvYShVwE9gM+lUaImCZeseKrs8cFAzFHAcoreubC/sDIIe9+K6ywPHIjhO4P4j2cIq/Z7e/WWbfqIyuSVN9xffG/q4enfbUqqLiGw1xiwqPq4rfyU2yhWRcleMlYS9hVWWNNiLr3mZFmI7B5iUOSHCtp3E5JY0ly84w7dBfbkcOpLlxq5toRnA5ZoXyv28dbJJBir+SixUGrFTjgDZzEW1IortHOBVzwrf1smrZVwzt3TOZ9OOA7FeU3EoaVxRVOV+3qMpsqvRUbOPEgs2s0dbaya0/EC5RO2HWw1aM2muWHhGYVU9KZO2mnG84ZlBwu6WQA4r3ZxukmE2/1Ip/kzKWYnbPu+UiG9hubDnVfN7MtZRs49SVeqRIu81F9ViByAwLCnNO/EE2e+9zuSgc7v3G07U7m+zRPIUJ4iVgvczsTWJdx3eUc7hJax/cBJLKYxVVPyVWCgnYqfUFWfQ46PY5yuheGXqlxxVLn4rfVf4bathW+Zu2Hlh+GdiaxL/3cd2jyhEV3wO22QWlKPRyLkAow0VfyUWooQMesU7LAa/GJuteMuug9yxtfTa6yJESsbyuw6Ib6UaZOLZ1z9gnfCCXt/doayYO5U7tvYFfiZBGcBBSXZ+n3fx2KM+T3MB6oOKvxILYTV7im3ZQTH4foJjywL+3uO7ra0P0ykBQ2GCAUcYP7p0JotmTYnkL7B1xYrL2Wywh51OyqStzlHb6xeHd7544A02/+ZEE5jpkyewfuPz3LChh2mtmcA6RGFlGQA+e3uv79htK3nNBUgOFYu/iMwA/hM4HRgCvmmM+XsRmQJsAGYDO4EPG2MO5Z+zBvg4kAM+bYzZWOk4lMqpNAQvrGZPlIV2qTbhoJ63K98+g0WzpgRek3uf7TRDxvi+B2Er31LIGTNiB5BJpxDBWvZi1aVzWPWj3hFO3zeODtLV3UdnRxs3dm0bJvwAv37pcOHvvv6BER3HvISZYtz3pZQdn/sZqHO3/sSx8h8EPmuMeUpETga2isgDwJ8APzPGrBOR1cBq4HMicg7wEWAeMA14UETeaoypfciGUqAaIXi2sMYg/ASnq7svtNOVH24DFT+hKRakI8cHfVfAtvG419YkwRNQVIqdvKsuncMNFj/Gvv4BOjvaWHvX9hGO5uyQ4foNPc61vRq+M8kOGTLpJo5mh0ZMPlFMMWEreQ3tTC4Vi78xZj+wP//36yLyHNAGXAW8J/+w/wB+Dnwuf/wHxphjwIsi8gKwGHi00rEo5RO1uFopu4NS7eLplHD42CBnrr43lqgWmxnJT5DSTUI6JcNW0n4CWPzcOITfxeCEkLqTlS2KyZ2QXg2IMCrFJHU0O1TIZi5n19cIrRqVkcRq8xeR2UAH8DhwWn5iwBizX0ROzT+sDXjM87S9+WNKHYlibil1FRdmF0+nhInjmnl1IFtwALsr2b7+gVgiePyuy0+QskOG1kyaieObA6t22mzccdE/kC2YbWympSPHHdNOXH6Haa2ZqhUR09DO5BKb+IvIScAdwPXGmNdErLZEvzt8f00ich1wHcDMmTPjGKZiIUoIXqmrOD/xKjZtuM9btu6hsgqdheFntrEJz6sDWXpuGl4Lx1v5My7ccsq2c7rvp/veFJt3Dh3JsubObVx9ftuIaJ5SiTvSpnhnaHMoB5nT1BFcG2Jp4ygiaRzh/64x5s784d+LyBn5+88AXsof3wvM8Dx9OrDP77zGmG8aYxYZYxZNnTo1jqGOSaL0VY3SUi+sPWHx+Ts72jhv5qRhj33nWVPYue5yNq++cNgPuxorQZuwRW3b521LGPeYggTX+150drQxcfzINZrbvD2s729LuolUfiGWEmHZWVNC2zGWi18bxzeODjpRVx4EWDF3auhzg1pAKpVTsfiLs8T/FvCcMebrnrvuAq7N/30t8BPP8Y+IyHgRORM4G3ii0nEo/kT9UUXp0xoU/eF3fr9ok82/OciNXdtGPL/UJJ+WdFOg6NlCNCF679hyHNa2sRS/p50dbUxuSfs+vvi9CDKddHa0sXn1hb59f9MpYVxzipwxhXDSna8MsOrSObzoMwFXis2c1lwUUWSADU/uGfYdrEXDcmU4Fdf2EZHlwC+BbTihngCfx7H73w7MBHYDHzLGHMw/5wvAn+FECl1vjLk/7HW0tk95xFlLpZRaOm2tGX736lFf+3iTwG+/MrwbVTl1enauu7zsctBeE8OkTJpsbqjQOrE1k2btlfMK/XTj4LaV7aGOZ+/Y4UQEjVgiioJq9LS2pHl1IOv7vHRKWP/BhcMa2sRhajlz9b0lvV/enATbc92S2VVlYAAefhgefND596lPwZ/+aXVfs4bYavtoYbdRTtw/qqg28LDiZDYx9AtfDDtHJQLW1d3nGy+fbhJOmtAcmx/CNiH5XXMm3cTgkAks3OYVcD86/vanoWNvzaQ5fHxw2OvYfDI2vO99OeG4O/PfwZoWfMvloLsbHnjAEfvNm+HYMUin4Z3vhM98Bt7//nhfs45oYbcxSqW1VGwJOmGrvEmZNK8fHbSKgRuL7hUY9/+/ur0nUgilG2kUFb9rWXvXdl+RzQ4ZjGFE+GcxkwMyZL14TRjF7RcPHx8seuyQ3ymGkW6Swvt1Y9c2vv/4noJ555olMyKNyW+SLaX8c/HOxe+zzqRTgbu5oMim2JzRxsBvfnNiZf/QQ3DokHPfggXwyU/CJZfABRfAxImVv16DoCv/UU65ZpGw54at/tMpYfHsySNs/sV4x1KO6WdyS5qj2aHQ6/M7d7pJhpV+qAXFYhi2Qwpi57rLubFrW6wNYIoJWnkHlXV2S1i7E6xtN+c9f6zRPgcOOCL/4IPOCn/XLuf4jBmO0F98MVx4IZx2WnnnbyB05T9GqaSWSpATLqy8QTbnOBcz6abAlaw3VLQcB2vUGkE2Z2QtSYn4VtCshO8/vqfCMwRTTnG5IWNGmBRtORvFkU1li/2RIyfs9g88AD3515s0yRH5Vasc0T/7bKeqn6LiPxYo90cVFmUCwbX09/UPcOvK9tDVfF//QMnOwjCKx17vpKIw80fp53MC9aqZcAbQMi5lrfdvMykanF2BO0l0drRx893bI8f7RyKXg6eeOmHKefhhOH7csdu/4x3wpS85Yn/++dCsMudHLHH+yugkLB7eDTO0hVy6maNhsehQ+QrYNkbb7VrihniGvQdemsAaCgrQJMKydQ/FMLpgjhzPWev9r5g7dUR4qUtxSPFN75vnG4rqlvOw5Z+ceFEDL7wA//qv8MEPwtSpsHgxfP7z8PLLToTO/fc7tvz/+i+48UZYskSFPwC1+StWfO3knpIMtq5WEN3uXg28r+11htaDcnwamXQTV58/PfZ+vi6l9DIIwo0ICtr9ecM5g/o5gM93xmu3f/BB2LnTOe7a7S+6yPk3Buz2laChnkpZRP3BQjS/gvd81frmfWzpTG7pnF91Z2hUip2aNhOIS2smzbHBoapPklGw9RqA4eHCs1ffaz2HX1hv+80/HeEEnpA9yh8e+g23vumAI/Zeu/2KFScctWq3Lwl1+CplEWbbd52rtmzRYmehm9YfJPyVRMDAiVLO1XaGRsXrb9iy6yD9IWGYUfMcasE1S2ZYq6q6prSu7r7Az8yvMmz/QJamoRzzf/cCy3b1snxnD+f3Pcv43CCMG+fE23/5y47Yn3dexeYbrRs0EhV/JZAopgqbM9WvCmjYSrxS4YcTE1K1TT1hBdpcvCJZbnnqejC5JV1o4l48bm8Mflg/4cL3I2+3//XN/8S/PPck79zVy6RjTnOZ7af+Ad8+/0p2zFvMrd/4VKzx9tpTwB8Vf8VK1BLGNmdqqaGbQSYGP8L635Z6vlJxo5mCykCUIpJJIpNOcdP75gFwS+f8wI5oQZPfmw73c/nLz8EnfuyEYO7ezSpg7ylTuX/OMh6ZtZDNsxbyysRWwDERxZ1opT0F/FHxTxBJ2pq6q6Uw8QzKwiw1vHLImMgZsxC8Q3BNTNW0+bvRTLaGMxPHpUinmrghn81cDedtuUxuSdMyrnmYOW7TjgPW715QuLB3kp2QPcriPdtZvrOH5bt6OOelF50HtbY68farV3Pljgk8PWHqCLv95Ja09hSoISr+CSFJW9OoK/621uFN2ouFo9RmI65DuVIECl3Aqklf/wBnrbmPa5bMGNEJa8XcqdyxtW9Yc5o4TFo23HO3pJs4ElIewl3Vx/K9yuWY37eDZXmxP6/vOcbnBjmWamZr2zk8+8nPcc61Vzt2+1SKru4+ntvTO6JSXTolhZ1G3FRa4mS0otE+CaGmha0CiGLjDwtfdO/fsutgSSvv1kw6FmfnxHGpQoXOUqikH29K4JRMmv4jTgjs4WODNXXc3rayHcA6aReXXChb+N14e7co2qZN0N8POHb7X85u55FZC3lixjwmnHLyiM5oth1QayY9opFOXFRS4mQ0oNE+CScpW9MwO31xnfy46rBPbkmHRsGE4VapLEf4K/UP5MyJUhO1Nu80iRNFdMfWPus1uCUXXNPiDRt6ok8EL73kxNu7gr87P6HPmgVXX82Tbzmfz7w0mX3jTi48Jd0kHD4+vC1n0KIiqB9xpVRS4mQ0o+KfEJKyNQ0SLr/VUhyTlmuGKKWcsx8TxzeX9fy4Sy9USqnmoSFDaCLbtNZMdNPikSPwy1+eEPveXue4a7dfs8YJwTzrLBDh7cDfFPmrjhwfHOG7GcjmrJNstb/n1epR3Mio+CeEuEraVlrb3iY8ts5YQZOWnwAAhUbpffmIHHencHywfAFuzaTL2iW1ZtJcsfCMumYBe3ETp6LU4/cSNHb3e2TbpX3t/mfpPL73RCbtI484dXLGjYNly+Dv/u5EvH3Kv5xDsbieaUn6yhkzYrKNu4+wEg0V/4QQZWsaJuyVOo2DQhG/9mH/xiG2SWvF3KlseGJkklU6Jay90nHsFY+1EsrdMWRzQ4HmklrjroDjaiLjnbRvcCtrGsOZh/YVnLTv3PU0fMGJt6ejAz79aSebdvlyaGmJ/FpRGrt4S0KoCaa+qPgniKCtaRRhrzSeuZyVs23SWnvXdt+SyRPHNdPZ0caydQ8lwtRi8w+IOKvwGld9LmRAx5GjMMxM9/vf88c7H+WcZ59g+c4e2l4/AMDeU07l3jnLeOTMdjbPXEhm2ulliXHUxi7eSp9KfdFonwYhSjRQpS0bba9R/DphdHX3Weu3Q/TuV/XmtpXtFfshihnf3EQmnbKe0y2cV+lrnpQ9xjfPPMw7X+xxTDlPPw1A/4STeGTmAjbPbueXszvY3Xr6iHj7Upr9hK30Y4syUspGo30anCiO1UqdxqsunROp6UYYN9+9PfD+RhB+cBqQTBznb+MuB7fgnIvfZJvNmUjCX7wzSA3lWLD/1yzb1cPynT2c17eDcUOD5MaN56kZ83jo3dfyq3OXsKmljaGm4GuKsluMstIH/8YuSjJQ8W8Qogh7pU7jzo4260q3SaTQbzWMSsW92mUZSqGcsFEb9/Tu596n9xdyAcr1c2TSKc6bcQr7n9xWEPt37N7GKccOM4Sw/bQ/4N/ffhU9bz2fn099K0fTEwrPjVoLM2yyj1q6Y6wnUiUZFf8GIUzY3S24N5yuLcJWu9iJfMXCM7hja9+IH3bOmJpkHCct7DJOvJNqORm/bz58yHHS7uxl2a4epr3+MgB7Jp3GPXOXs3lWO4/MWsChlknWc0R9PT/RLrUct0bxJBsV/zrjV/LYr8ZKUDSQ3xbc61wLeu1iJ/IdW/u4+vw239BHP3OAXwRSJZm6UZrDNwph70OYgLYcH2DxnmdYvrOHZbt6eduBnQAcmnAyj8xawDdmf4TNsxaye/IZJY8trAzEirlTh322k/IJdNlc8KhrYeNPUg2sRkYdvnWk1FIKNsotDWF7XmsmzasD2VDnsS1t/urz29jwxJ6yGqS7ZQpW/bKLaEYAACAASURBVLA30vNHw07BzW5+0/gmznzxWZa+2M3yXb105O32x1Jpnpx+TsFJ++ypZ4ba7cNwd4W2chCTW9IczZbWUKYWJRPGeqmGclCHbwKJYjeN4nwrN8vWdn//QNa6avWaA9betd03tLSShCm3Mczn7ng6NM6yNZNm7ZXzarZTiL0wmzGcdXAvFzzVyzt39vCO3U9z8rEjw+z2v5zdwZa2t3EsPT7OV2Zf/8Dw2P8iSvXb2JIA40bLM8eHin8diRpBE/a4cqN8gpyOIk7YYfE2//CxwUKjbZtJoxJn7b7+Abq6+zg2GFyZEpxyDgCHDh8r+/VKIQ7hn/rGId65y99uf/fcC3h4dgePzpwfaLcPI8qq3f1uVOJ49pIzpiC+xeYiEQpO7kpNNEmpgTUaUPEvg7hsjlF/eGEibqtb7yYMufj5F2xVNw8dyZJuGhkb0j+QZdUPw8s9l8u01kxoqKhLX/9AYD5BEpiYHeDtu/3t9ptnLeQbs9t5eHY7e1pPj+X1vKWR3R1R8Y7F64i1BRKMb24qyW/TJCfMiN7XK3ZyVxo0EHcNrLHsP1Cbf4nEaXOMy+bv1wwbhpfJtY27SfzDGatZe96G6y9IQtP1ckkN5Vi4/1f50gnD7fZPTJ/H5rzYx2G3h+Gf0+SWtG+d/ihlQYrvB0K/m+VSSZnyav/+RqP/QG3+MRGnzdEvgieso5IfthWa97ht3K2ZNJk0w+5LN0lZztpKSIlw9flt3NO7v6avWzF5u70r9kt3Pc0pxx27/TOnn8W33t7Jw7Pbq2K33+lJnvKWal6/8flh3xu/cgpRV7zV8KdUYqKJszzzWPcf1E38ReQy4O+BFPBvxph19RpLKcRtc6xVnRPb+F4dyI7oQmWrxllNcsaUHSFUa2x2+92TTuOet8Vjtw9DoJB0F6Xuk1fsJ6SbGPCEedrMMe53M8oOtRTc8tLlCnhcv5mx7j+oi/iLSAr4J+ASYC/wpIjcZYx5th7jKYWk1N33YquVM7klXfg7aNzFP6bZlnK81SaK8Ncj+9eNt79gZw/LdvYw9+VdABzMnMIjsxbyD7MWsjlGu30UDBRWqLYV7Gdv7y3c9or3gE98f9CKt3i13dqSxhhn4TApk+bVo1mifiRuxdcktCxN4m+5ltRr5b8YeMEY81sAEfkBcBWQePGPq+5+nNz0vnms+lHvsMic4p6oUcftRvJUSiHe/8k9oYlBUWmLKTIljObcIAv2/5rluxyxP2/fDtJDuYLd/sfnrmDzrHa2n/YHGGka9txyW0iWg7tCtb0nOWNY9cNeBo2JJM5BK16b6WjNndsiC78bDpoUc0sSf8u1pF7i3wZ4i73vBZYUP0hErgOuA5g5c2ZtRhZCElvCRRlT1H4B7gqsHNpaMyPOvWjWFG6+e3ssZqSqCb8xnPXKXpbn6+Qs3f00Jx8fKNjt/+3t7+eXs9vZGmK3z6RTpFNNQG3Ef1LG2dkF7YZKMaO5K95S/AGlmIKG8uGgttyCWptbkvhbriV1ifYRkQ8BlxpjPpG//d+BxcaY/9v2nKRE+4xmbFFDLm0h/oCgWkJx240rZeobB1m2q5cLdnazbGcPp79xEIBdrafz8Ox2Hp7VzqOzFtCfOSXS+UTg1g+3c8OGnppFSTWJ0089jtcT4NZ8dnXUCBhbCXEbbpRPuRnpSnkkLdpnLzDDc3s6sK9OY0kktY4/7uruCxT+dJOEOoLduPs1dz7N0eyQb22iesXltxwfYEm+Ts7ynd3MedkJJ3Xt9g/HYLe/YUOPta59NYjLNy7AR5fOtDbZsZlkbDZzEWhukhFmyMPHBjlz9b1MyqRHJBAKI/NSlOpSL/F/EjhbRM4E+oCPAP+tTmNJHJW2YyyH9RufD7w/O2SGCX9QHoDrUOzrH+CGDT1cv6GnsCuoh91++c5uOvY9T3oox9HmcTzZdg53nnshD89q51kfu305uHqflFLUUSnerZUSAeNnM4f8e2FO1CxqbUnzxtHBwuKifyBL8TtugDu29rFo1pQxY3apN3URf2PMoIh8CtiIE+r578aYaGmdY4BaO8S6uvtKFuSoEuc+zp3Arj6/zbdkdMUMs9t3s3T3toLdftvpb+H/W/x+fjm7g6fa3sax5nHxvnbCECHUCWsz5ZQSAeM+1684XHbI0DKume4vvpdl6x4asWP0K94xlmLsk0Dd4vyNMfcB99Xr9ZNMnPHHUZu+14KBbI57evfHlsVrs9vvbD2Du855Nw/PaueRWQt5NXNyxa/VSEybFGxbDyrCVmoETJADt69/ILA1qB9ubaex6oStJZrhm0Diij8ut+l7NekfyHLn1r1lPXfisSMFu/2yXT0Fu/0rebv95lkLeXh2O3trGG9fL4JKWbuLBJuQu8IfJLKliO8kSwVYofQIrdaWdCJyAMYCKv4JJGqhtjCimI/qkc0Y1ETES3NukIX7f1UQe6/d/onp87jj3IvYnK+TE4fdvlEQsDbcgROLhFIaABWLbFSh7eru4/DxQd/7gixP6SYBYZjTN5NOYQyJyAEYC6j4J5BNOw6UdNxGJU3f64IxvOWVPYWInCV7ninY7Z8+4y18c/EHeHh2+5iw2wdhgHuf3s8pmeYRtvRiE40tOcvPTl+OyK7f+HzJSXyuk9l9vndiSkoOwFhAxT+BxGXzL7fpexwIzhY+LLnrtNdfZtmu3kJhtNPydvsXJzt2+82zz2PzzPk1s9tPHJfiyPEcLREydatdaiKo1aLf++o2t4nSutM27lK/Y6U+vjiWv3istkJyY6XkQi1R8U8gcdj8u7r7OOKzHfdbGW7ZdZDvPrY7cgRPlHLP7kqueGI56dgRluzZ5phydvby1ldO2O03z25ncz7efu+k00inhOYm8a1FUy22/+1lkZ3g45qFgWz1xD+qecxl4vjm0FV7mI/HzRqOiu272ppJc2xwqOTSCWO95EItUfFPIJX+AGzZtLaV4aYdB0rK1DQEhxN6m8dLNst3/+GHvHNnN8t39tC+73mazRADzeN5YsY8fjj/YjbPbue5U2ePsNvncia2ukBRaMtPrlGd4LWclKLgRtcEOWjDVuoysn9PAT8Hse27uvbKEw1lSonaGeslF2qJNnNJKKWEuxU/1paJ65c+39XdV3LWbWCiljG89ZXdLH+xh4v6nmbxnmdIHzlMTprYdvpb8hE5HWxtexvHm0tbZVYTbxRMqWUL4iKuBjpBDUmihF761WgKanwCKtZJxlbeQcW/wSm1Zs5tK9uH1Xgv1d7v/uC9E4Zrt3cctT2cevgQ4NjtH/uD89hyVgcPnHEur004qYQrqy2ZdFOhJMXhY4MltTCMA1tZ7nKx1ckJ+8z9Wj66lTi1Hk9jkrTaPkpMlBqnv+pHTo13Wx34INxuW51nncymPVtpf36Lr93+4VntPDJ7IXsnnQY4wvZ6jZvDlIq3JEU6JTXvZnY0ZhOSbXXvTvxr79o+YoLz23m4EUBjvfHJaETFv8Ep9ceXzRluvns7nR1tkZ/bnBukff/zLN/Zw7u+08vQ/uf5+1wukt0eoP9Iti5mlHLJ5gwt6aayxT+dEtZ/cCF/dXtPpOJrwsjY9kiv0yScNGFkuKfLjV3buKVzvq8Jseem9444bpswgu7XKJzGRcW/wSknTt8VC1tmJsbw1pd3FdoULtnzDCcdHyjY7f/XBSu59ouf4IGWWdy08YVQc4UrEKWMM5NOIZiSI168VGJDr+R1x6WaSvKjRB1jugnSqRPhnydNaObyBWdYI7W+m08U9NZSCkrmsvkDbJFbGoXT2Kj4NzjlxukXZ2ae9vrLBbH32u1/O3kaXee8h1/O7uDRWQt4bcJJCHDtihVcCXx1085Q8e/rH2BySzqyKcXNYF00a0rZJaCjFDcLo9w4/mp18soOQXboxKR06EiWO7b2WScPA75ZwLZkriCB1yic0YeKf4Pj/VFGXVm3ZtL880+28u4dWwpif/YrTmO1l1smsXnWiXj7vkmnjni+d6sf1XR06EiWdCogjtCDwQk/vaVzflnin2oScjHY6xuhPPNANhc4SZWSzBUm8FHKPtzYta0w4aREuGbJDG7pnF/KJSk1QsV/FOD+KINCFNO5LO37nufdu3q45vVfM2lbN81miCPp8Twx/Vw2LLiEzbPb2THV327vUrzVL8XsVErMvitO5ay+Tx7fzMTxzckpW1FlcsZYTVy2989mqy+eANw+D1FW+Dd2bRtWkypnTOG2TgDJQ8U/gEYrLTtMiPN2+wt29rB8Vw+Ldz/DxOxRTFMTsmgR337PNdx/+rl0T5sbGm/vF/ftsurSOVXpzuWK0zVLZpRc/rnWYZr1pq01w4q5U0fY/jPplG//hCBbfSWNhL7/+B7rcRX/5KHib6EW3bTinlz+Z8cp/Pyf7mXJb55i+a4eph7uB+D12Wcx8bqPw8UXI+95D7S20trdx9N3buN4iK8gLI67s6MttgbtXg68fpTZq+8FYFxKOF7CrkEYOxOA1ya/aNaUYd+nFXOnsmnHgWGmobaixK3i718ljYRKNT0p9UXF30K1u2nFMrm8+ir813/Bgw/Cgw9y2XPPcRlwaGIrv5i5kGfOWcy4Sy+m65Vm5we+I8OqWYeBw4XrCzOrhEVzdHX3VexY9cMr9qUIP8STJVsJcWTquiLtF4/vUtyUxWuTL/5+5YwZNlHYvn+2wIEoJjTbdykVVDNCqRsq/haqndRS1uRy/Dg8/rgj9g88AE88AbkcZDLwrnfBx53V/eT587mqqQlT+IE7Y+7rH2DVD3uH1VEPshdPbkn7jsVdMfb1D8RWkmA0Ecf70Ze3t786kGVyvgeuN1JKcExiXrEvLvER9P2yff9sAi751whamNhMdNcsmVHClSu1QsXfQrWTWiJNLsbAM88UVvaDm35O88ARctLEjulzaP6TT3JgyXJu/P3J7Hojx7RshlVDb6azyXHY+v3A/UItDSNXq4IToVNcKKx4xajCXz3c79+hI1lSTcNXz96G58CIVbwNt02i7TG2xYCB0F2va9fXaJ/GQGv7WCiOXHD52NKZI2yr5djqbQk17fIGXXMGCoLP738POHb7u958Dv81YwGPzZzPaxNOsnZDck0Brs08Km7BNr/6Llef38amHQdiiaBpEhjf3JS4qphxUu1a/y5tJSbQTW5JczQ7ZDXvBBXtE+DFdZeXNU6lfmhtnxKxdc269+n9gRmTUXETaprfeI2lu7exbGcP79rVwx+8ku9ve+qpcPHFcNFFcPHFXPa9F0b8KP1W8e7WHkqzPbuOXb9JaSCbK6nefxhDJnnlkOPEnSw3PLmn6iWpSzFD2tokeu93nb5aymH0o+Jvwfaj8otqCbPVe+2xM09q5pbT36BzVw/v+sl9THqmh5QZYiA9gdfevhSuvsER/fnzhxVX39cf3lzEpa9/IDD8Mp2SEbsF17Fru+5G2B9m0vXbTaREGDJm2E5w0awpwyKh3Mm4NZPm8PHBWCaGoNIZrZk0E8c3R2qTCAxzHmsph9GPir+FUmvm2ESz66m9/P//ejeXvbCV5fk6OS3ZY5imJqYsXgw3fgEuvpjM0qVkxtn70sbZa3f9BxdazVaJ6ulbIqVGBcVJzphh5bIhOCPW6zSPQjolYIbv9ryCbGuoErVNYltrZljUkPvYRslxUUpHxd+Crc4JGN/V5bD2d3v2FGz277rrPjrfcOLtX5gyndvnX8Ijsxayc8Fifrr2St/XLo7cWDF3qm9LxnLKDrs/ctsP2e+6K43oqVVEUBwlHYJINzl2fNvLlGL+834GYQ1W3A5sECzIUcQ6aoG2KKUclMZGHb4B+CXB+CU0nXL0DS76/XPcOuWAI/q/+pVzx2mn0fWmuTw8u4PNsxay/5SphefYnGdRG6xk0k1MSKdKSq5yncFbdh0MjMjwrkrLcVy6pYb7j2QLk1e5PoPJLWlaxjmmi0mZNNncUNUKpwXhxt3DyFW2F9f809qSxhh4dSAbqROb3zknt6S56X3BDdnLodEy15XKUIdvGfitfm7Y0MO4wSzn7XuOZTud7lULfvdrUmYIJk6Ed78b/uIv4JJLYN481n91U0nOs6gNVpyIjej2bVe8tuw6GKn+irvTKFX4UyKs/9BCXzEptUwDOD6W1wYG+agnyurw8dLMUpPzQlxu1q/AiCxnm0/Ffb+8k3JYUECtzSy6qldAxT8aQ0NOvP0DD/C9H29g4YtP05I9xqA00XvGW/nHd3yY589dwj9/4/+CIrt9qXXQo0ZvRJXk4n6un7291/dxbv2Vclo72l7Ly6JZU/j+E3vKMs24E1Q5k0cmnSqsnksNfXVxJ2rvirnUHZE3KMC28lZBVmqJir+N3bvhZz9zMml/9jN46SUAzp39Fu5c+F5+MWMBj85awOvjJ55oZO3jsC11VVepw3VyiLkhrP5KlJ2H5Mfp1o6Jcl033709kvC3ZtK8fnQwlhh5t0OWG/oa2HjegjtR+5VLKBU3wSqOmlFJMN0kYQxK+aj4u7z2miPybnKVx27PJZcUYu5PnjGDk7r72L7xed7oHxhWKMtGKau6KM1ZbA7UKM20w+qvhO08SmnY7RWHqFIZZ0E29zVdgb36/LbA3YOA1Va/bN1DZe2GvLS2pGOpGRVlAqm2MNei8KFSXSoSfxFZD7wPOA78BvhTY0x//r41wMeBHPBpY8zG/PHzgW8DGeA+4DMmCV7nRx+FD3zAsdu/5z3wl3/pCP68ecPi7aG6NlO/nULxCnvF3Kkllen1ElZ/JWjnIcCKuVN974Nk1/wZyObYtOMAk1vSvk7ysEktjppOxsRTMypsAqlEmKNOGtUufKhUn0pX/g8Aa4wxgyLyVWAN8DkROQf4CDAPmAY8KCJvNcbkgH8BrgMewxH/y4D7KxxH5bzrXfCLX8CSJb7mm1oSZXIpt8REWP2VoJ2HwXHa3tO7f0To4aSixKUkCb/Lvv4Bbl3ZXlYCU1RzXJAvoH8gS6ulb3KTCGeuvjfSZxk2gZQrzKVMGtUufKhUn4rE3xjzU8/Nx4AP5v++CviBMeYY8KKIvAAsFpGdwCnGmEcBROQ/gU6SIP6ZDFxwQb1HEZlKdh+3dM4fEdq5bN1DhYkkrI5P/0CWVT/qHZZ0VI36+a6QCtAUQ2vGaZ5EJm8oq9cvEJT/cMOGntBJzZ1QbRPA4eODvvkZ7uPd7Oy1d223xvaHFR0sV5hLmTSqXfhQqT72fn2l82ecEPE2wNvWZ2/+WFv+7+LjvojIdSKyRUS2HDjgX2tHqQx3tdeXt8v39Q9wx9a+QPMOOMXkSk0wK4W21gy/+cofsXPd5dy6sp1TJpxYp7Rm0ty2sp1lZ00p6ZzuNXV2tLHq0jlk0qlhorvmzm10dff5Prezo42PLp1JWGV6IdgZnM0ZxjU3hda47x/IsuqHvaz6Ue+wz2bNndtYMXeqU9TPQ7pJCrsXmwCHCXMpk4b7/nnREhCNRejKX0QeBE73uesLxpif5B/zBWAQ+K77NJ/Hm4Djvhhjvgl8E5wkr7CxjiZqFUlhW+3ZWvLVgnRKWDF3aiHztdh/0D+Q5YbbezAGJo5LceR4LpKZyVusz3bda+/abn2fb+mcz6JZU/js7b1WgY8yjqhJarbCffc+vX/ELylnDDffvZ0bNvTQ2pIesbuoxLTlN2loCYjGJ1T8jTEXB90vItcCVwAXeRy3ewFvB4fpwL788ek+xxUPYbbXOCcG22ov7nLETYK1LEIx2ZwZ5pT2e5o7vMPHc4UqmmF5AN5rtV13/0A2sGmJe3zVj3qrXrHThp/DesicOH7oSJZ0SmjNpCNlGLuUmpOiuQmNTaXRPpcBnwPebYw54rnrLuB7IvJ1HIfv2cATxpiciLwuIkuBx4E/Br5RyRhGI0G2VxjZuKOSicG22osi1qXUFqpm2Z2BbC5SAlhry4n6S0EO3DDHaGdHW2B7xSSQzRkmjm+m56b3Fo6FfTd0NT+2qDTa5x+B8cAD4tgwHzPG/IUxZruI3A48i2MO+mQ+0gfgLzkR6nk/SXD2Jowg22slE4MftkJuUcR64vjmutXaKQfvZmbVpXOsJRqiRPW8GlH4i+scHT42aIn2Gfme25r1jG9uijTxeL9HUSN5dDU/dqg02uctAfd9Gfiyz/EtwLmVvG5UGjUDMcj2ahOmsImh+Lq9782kTJoJ6SYOHcmWFJ/fP5Alk07xsaUzy+rylUmnEAxHalSD32vS6exo8y3SB9H61UYJ/fRLAPQrn1HIEGfkqtt2LEoJDq+tXuPylWJGbYZvo2UgesXY5rALqo45rTUTOVqj+L1xRdyWABWEmzxl6wJmwxXGtXdtr5n4w/Cyy5cvOMPXXBSlX21QPkRQjaMw00rQc1y6uvvybTCd125JN5EdMtYGPaBx+cpI4gz1TBRh5pEkURxueehIFsQJaRQcofzKB+azaccBX+EXKMR/+1F83PbelCr8Lq6AhIWHurjZtJ0dbZHNJy6t+b4JYaGSNrzfAVurTnAWC8vWPcSZq+9l2bqHRoSAdna08ZUPzC/00HXH435WYT6Dzasv5MV1lxfeh6i43xWv2ccgrHz7DNpaM8O+L97zlhv+qYxeRu3Kv5FWOn5i7Oews7XgMziCUlyu2aVYlON+D1wBCRJTl+IVaamF7A4fG2RyS5r+I1lrO8TWTJorFvqv6uHE9Qe9D8IJ23+S7OO2idvdfdkoNZJHGf2M2pV/I610ok5UtrG3tWbo6u6zxuYXi3LQe1DqejpK/1/3vH4r0lLFJztkOHQkiyGfVWycSqbu+W9b2U7PTe/lls4Tq/Ji3OsPeh+Kd1hBu0Y3Q9q2S4iTchc13p2K7bNQxhajVvwbKQMx6kRlu6YVc6ey5s5t1tj8YmEIeg9smXg2XAHp6u6jyWKKaWvNWE0cnR1tTPaEYJZKdsjQMq7Z9/xh3wG/+4Ou3U9g/TKkgzKFK6WSRU0l5iZl9DFqxb+RVjpRJyrbNW3acSAw8sPbjGTZuoe4YUNPcaHSAimRyNE+bj9gVwD9Jp8oE+5N75s34vpLwbbqDfsO+N1/68p2646hSWSEqNfat9RIixol2WgP34RQSVjqmavvtQq2N4wwLDwwk05FrlnvjWixRfmkRPjah/1bOhbjLQddKqW8ThSCupkVR/LY3ntbj+a4xteIIcxKfdAevgmnEuehzWmaEhkm0H5i5jYcd0UkSIAnjksVErrGN5/YNNpW3kPGRL4m9/qDJrKWdJNvWGjOmFjCeIvDbY9mR9YMcuv/uI9rslTwrKZvSROxlDhQ8R8F2CI5vCvUIIEuXqHaShd7M3n7B7IFwbVNPpMy6ZJXqZMs9e5dU8wRy3UMZHOF/sTlCGPxaj8o7LV/IFsYY7mmLkWpN6PW5j+WCLJtu3Z+22q6eIXa2dEW2ebv2rZXXTpnRIlhgNePDbLqhyNLEtucoV3dfRw+PjjiuFuuOCyiJWcMq37UW5azNUrv4iBSIon3LSmKF135jxL8TAFBtmuwr1BLaXS+r3/AWiohN2QofuWgkgLrNz7vWynzpAnNdHa0RfIJZHNOaeNSxbfS3Ae36Uw1UBu/Ug105T+KCVrNBq1Q/SJKbLg7h/4SsoOD6hP54Z476rjcSaiU+PswG727qg8KS61GqGetQ0mVsYOK/yjGJqYCgXHexWYkWykFt6wElObgtJ0vLIa9uKRCEKWK5qpL51hX7t48hShhqXGGejZSmRKlsVDxH8XEkRB068p2TsmMtA4K8NGlMwsTSNS6PuCYSPxW41Fi2N1x7Vx3eaHOTzGtmXTJomlr0+j3+t6J0UYpZqSgHUojlSlRGgsV/1FMpQlB7uq52Jbfmklz68r2QhP4ru4+7thamhnCthr3hpBObkkHOk/XXjnPt5ft2ivnlSWat3TOLyR5BTlvvZmyYSUkXGwCH7ZDaaQyJUpjoQ7fOlJtR16lnZlsPoOJ45uHnaOSSBlbIxqAoyGlnoOuz+YcdrN0g0xepSalFfdAKJ5gg8qLh9XZ14JsSrVQ8a8Tteo3UElCUNTVc5gJImVJhPI+v9RmI8UT560r20fU9fGLdIojIaz4s3PrIRn8G7gEXVvYe6ytFZVqoeJfJ6rRWSnunURQRzEvrQFNYNxks6AwzVIa0UC0idP9/7O3946YeCp9n/0+O1f4/coqB11blPdYM3qVaqA2/zoRtyOvGiGBUX0GQeWhXJt50HWtmDu1JNt2Kc7cqJVOS8H2XFsDmKBr00JtSr1Q8a8TcTvyqhESGLUyapRuXEHXtWnHgZJE0LaD8B53J8Og8ZRbh992LW4DmOLJN+jaGqn6rDK6ULNPnYjbkVetkMAoJoegblxex+X1lk5kbpaw+/gws5XNh+DNHwhyQnt7IJTjc/H77Pwa37uTr2sKCurbq2Kv1BoV/zoRtyMvqn2+GoQJOzjXu/au7b5F27xJXFGu32bK8R4PmvRcH0S5Phe/zy4sa1kFXkkaKv51pNSwwqBJop4hgbbaPjB88ll75bxYxmirPeSNubcJstuAxtYPOepOqfizs/U00Hh8JamozT/hRHXk1tt27Ff2ICw7ttwxRvEPhD0mbp+LOm6VRkM7eSUc24rSFlZYKZWEi9ay+mSU1wp6jF/F0+IeCNUYk6LUGlsnLxX/hFPLNoHVEMQko2KtjAW0jWODUktHbjUSz5KMOmGVsYza/BNOLW3JWkFSUcYOuvJPOLWs7VLPcNGkoSYhZbQTi/iLyF8D64GpxpiX88fWAB8HcsCnjTEb88fPB74NZID7gM+YRnE81IlamSe0gqRDJUX3dNJQGoWKzT4iMgO4BNjtOXYO8BFgHnAZ8M8i4tou/gW4Djg7/++ySsegxEO9w0WTQrmlMrTlotJIxLHyvxX4G+AnnmNXAT8wxhwDXhSRF4DFIrITOMUY8yiAiPwn0AncH8M4lBhQJ2j5vo+x5jBXGpuKVv4iciXQZ4zpLbqrDdjjub03f6wt/3fx2HR+8wAABiFJREFUcdv5rxORLSKy5cCBA5UMVVEiU24CmDrMlUYiVPxF5EERecbn31XAF4Av+j3N55gJOO6LMeabxphFxphFU6dG7xGrKJVQboSVtlxUGolQs48x5mK/4yIyHzgT6BWnmuJ04CkRWYyzop/hefh0YF/++HSf40odUSflcMqNsFKHudJIlG3zN8ZsA051b+ft+YuMMS+LyF3A90Tk68A0HMfuE8aYnIi8LiJLgceBPwa+UckFKJVRq3aSjUY5vg9tuag0ElWJ8zfGbBeR24FngUHgk8YYdzn0l5wI9bwfdfbWFXVSxos6zJVGITbxN8bMLrr9ZeDLPo/bApwb1+sqlZEkJ6WanxSldmh5hzFOUpyUGiOvKLVFxX+Mk5Q69NXoQawoih2t7TPGSYqTMknmJ0UZC6j4K4lwUmpROUWpLWr2URJBUsxPijJW0JW/kgiSYn6KgkYlKaMBFX8lMcRlfqqmOGtSnDJaULOPMqqodsioRiUpowVd+SuJotJVe7UzljUqSRkt6MpfSQxxrNqrLc5JSYpTlEpR8VcSQxwmlWqLs0YlKaMFFX8lMcSxaq+2OGurS2W0oDZ/JTHEkehVi5DRJCTFKUqlqPgriSGuZigqzooSjoq/khgaKdFLURodFX8lUeiqXVFqgzp8FUVRxiAq/oqiKGMQNfsoVUWLoClKMlHxV6qGFkFTlOSiZh+lamgRNEVJLir+StXQImiKklxU/JWqoUXQFCW5qPgrVUOLoClKclGHr1I1NGNXUZKLir9SVTRjV1GSiZp9FEVRxiAq/oqiKGMQFX9FUZQxiIq/oijKGETFX1EUZQwixph6jyESInIA2FXll3kz8HKVXyMudKzVQcdaHXSs1SHKWGcZY6YWH2wY8a8FIrLFGLOo3uOIgo61OuhYq4OOtTpUMlY1+yiKooxBVPwVRVHGICr+w/lmvQdQAjrW6qBjrQ461upQ9ljV5q8oijIG0ZW/oijKGETFX1EUZQyi4l+EiHxJRJ4WkR4R+amITKv3mGyIyHoR2ZEf749FpLXeY7IhIh8Ske0iMiQiiQyjE5HLROR5EXlBRFbXezw2ROTfReQlEXmm3mMJQkRmiMgmEXku/9l/pt5jsiEiE0TkCRHpzY/15nqPKQwRSYlIt4jcU87zVfxHst4Ys8AY0w7cA3yx3gMK4AHgXGPMAuBXwJo6jyeIZ4APAL+o90D8EJEU8E/AHwLnANeIyDn1HZWVbwOX1XsQERgEPmuMeRuwFPhkgt/TY8CFxpiFQDtwmYgsrfOYwvgM8Fy5T1bxL8IY85rn5kQgsR5xY8xPjTGD+ZuPAdPrOZ4gjDHPGWOS3Ll9MfCCMea3xpjjwA+Aq+o8Jl+MMb8ADtZ7HGEYY/YbY57K//06jlAlsrmDcXgjfzOd/5fY376ITAcuB/6t3HOo+PsgIl8WkT3AR0n2yt/LnwH313sQDUwbsMdzey8JFapGRERmAx3A4/UdiZ28GaUHeAl4wBiT2LECtwF/AwyVe4IxKf4i8qCIPOPz7yoAY8wXjDEzgO8Cn0ryWPOP+QLOFvu79RtptLEmGPE5ltiVXyMhIicBdwDXF+2sE4UxJpc3904HFovIufUekx8icgXwkjFmayXnGZNtHI0xF0d86PeAe4GbqjicQMLGKiLXAlcAF5k6J22U8L4mkb3ADM/t6cC+Oo1l1CAiaRzh/64x5s56jycKxph+Efk5jl8liU71ZcCVIvJHwATgFBH5jjHmY6WcZEyu/IMQkbM9N68EdtRrLGGIyGXA54ArjTFH6j2eBudJ4GwROVNExgEfAe6q85gaGhER4FvAc8aYr9d7PEGIyFQ3Wk5EMsDFJPS3b4xZY4yZboyZjfM9fahU4QcVfz/W5U0VTwPvxfGoJ5V/BE4GHsiHpv5rvQdkQ0TeLyJ7gXcA94rIxnqPyUvecf4pYCOOY/J2Y8z2+o7KHxH5PvAoMEdE9orIx+s9JgvLgP8OXJj/fvbkV6tJ5AxgU/53/ySOzb+sEMpGQcs7KIqijEF05a8oijIGUfFXFEUZg6j4K4qijEFU/BVFUcYgKv6KoihjEBV/RVGUMYiKv6Ioyhjk/wAsiSvK0QlC6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Проверка работоспособности алгоритма на двухмерном случае\n",
    "#Подобрал специально random_state с более менее линейной связью данных\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples = 1000, random_state=42)\n",
    "X = X[:,:1]\n",
    "my_reg = LinearRegression(tol=0.1**20)\n",
    "x1 = np.linspace(-3,3)\n",
    "y1 = x1 * my_reg.fit(X, y)[0][0] + my_reg.fit(X, y)[0][1]\n",
    "plt.plot(x1,y1, color='red')\n",
    "plt.scatter(X,y)\n",
    "plt.title('Линейная регрессия')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4vK_r-srni1"
   },
   "source": [
    "##Задание 4 (2 балла)\n",
    "Добавьте l1 (первый и четвертый варианты) или l2 (второй и третий варианты) регуляризацию. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "1Hx3yCoWbzEG"
   },
   "outputs": [],
   "source": [
    "class LinearRegression_1(object):\n",
    "    def __init__(self, alpha=0.485, l_ratio=0.1**10, tol=0.1**20, max_iter=10000):\n",
    "        '''\n",
    "        Для начала необходимо инициализировать параметры\n",
    "        alpha - это learning rate или шаг обучения\n",
    "        l_ratio - параметр регуляризации\n",
    "        tol - значение для критерия останова\n",
    "        max_iter - максимальное количество итераций обучения\n",
    "        '''\n",
    "        self.max_iter = max_iter\n",
    "        self.tol= tol\n",
    "        self.l_ratio = l_ratio\n",
    "        self.alpha = alpha\n",
    "             \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Метод для обучения линейной регрессии\n",
    "        X - матрица признаков\n",
    "        y - вектор правильных ответов\n",
    "        '''\n",
    "        X = np.column_stack([np.array(X), [1]* X.shape[0]])\n",
    "        y = np.array(y)\n",
    "        w = np.array([0]* (X.shape[1]))\n",
    "        n = len(y)\n",
    "        lol = []\n",
    "        for i in range(self.max_iter):\n",
    "          y_current = np.matmul(X,w) \n",
    "          cost1 = (1/n) * sum((y - y_current)**2) + sum(np.absolute(w))\n",
    "          w_gradient = (2 / n) * (-np.matmul(np.transpose(X), y) + np.matmul(np.matmul(np.transpose(X), X), w)) + self.l_ratio * np.sign(w)\n",
    "          w = w - self.alpha * w_gradient\n",
    "          y_current = np.matmul(X,w)\n",
    "          cost2 = (1/n) * sum((y - y_current)**2) + sum(np.absolute(w))\n",
    "          if cost1 - cost2 <= self.tol:\n",
    "            break\n",
    "        self.w = w\n",
    "        print(w)\n",
    "\n",
    "        return w, cost2 \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Метод для предсказаний линейной регрессии\n",
    "        X - матрица признаков\n",
    "        '''\n",
    "        X = np.column_stack([np.array(X), [1]* X.shape[0]])\n",
    "        y_pred = np.matmul(X, self.w)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "uVp729sBbzEW",
    "outputId": "3c133449-6321-41e4-f191-285db381c729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.09289583e-11  5.01486764e-11  4.53474549e-11 -4.94660429e-11\n",
      " -5.83686725e-11  4.95452741e-11 -4.77000113e-11 -4.95655155e-11\n",
      "  5.24858373e-11 -4.86504443e-11  4.35955530e-11  3.26829628e+01\n",
      "  5.43471615e-11 -5.36764855e-11  4.96738180e-11  4.69764718e-11\n",
      "  4.21687523e-11 -5.10498563e-11 -5.58764776e-11 -4.81311616e-11\n",
      "  5.28710360e-11  5.51490070e-11 -4.96503567e-11  8.26861728e+01\n",
      "  4.41575681e-11 -5.10200731e-11  5.33525149e-11  4.83470297e-11\n",
      " -5.08456600e-11 -5.06256200e-11  4.18270050e-11  4.72339715e-11\n",
      "  5.39166621e-11  4.44011967e-11  4.17856497e-11 -5.53240902e-11\n",
      " -4.88000708e-11  4.71130635e-11  4.57868759e-11 -4.32849540e-11\n",
      "  4.23883390e-11 -4.90687934e-11  3.96419499e-11  4.86094827e-11\n",
      "  4.77749965e-11  4.13175916e-11  5.60394317e+01  6.32578889e+01\n",
      "  4.55658284e-11  4.66184216e-11  5.74006734e-11  5.34669353e-11\n",
      "  9.01726076e+01 -4.83168283e-11  5.50414324e-11  4.86272106e-11\n",
      "  4.66292117e-11  2.05715140e+01  7.15561938e+01 -4.61325315e-11\n",
      " -4.37844351e-11  4.70673519e-11  4.82235557e-11 -5.43321269e-11\n",
      " -4.43025025e-11  4.98029191e-11 -4.37041633e-11  2.11466252e+01\n",
      " -5.07600554e-11  4.80559446e-11 -4.76467531e-11  4.95553260e-11\n",
      " -5.52250884e-11  4.91911904e-11 -4.62083239e-11  4.52484303e-11\n",
      "  4.27559370e-11 -5.38478069e-11 -4.96134679e-11 -5.23357799e-11\n",
      "  4.74909918e-11 -5.60893686e-11  5.18986193e-11 -4.56575258e-11\n",
      "  5.54832902e-11  5.15759900e-11 -4.84159330e-11 -4.95800753e-11\n",
      "  4.02144315e+01  4.57525389e-11 -4.41978207e-11  5.59992582e-11\n",
      " -3.68225575e-11 -4.49938349e-11  8.49118214e+01 -4.26771052e-11\n",
      " -5.45984405e-11  4.80423547e-11  4.51904229e-11  4.61953007e-11\n",
      " -4.27614772e-11]\n",
      "You are amazing! Great work!\n",
      "MSE: 2.500906324246984e-19\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples = 10000, random_state=42)\n",
    "my_reg = LinearRegression_1()\n",
    "my_reg.fit(X, y)\n",
    "assert mean_squared_error(y, my_reg.predict(X)) < 1e-3\n",
    "print('You are amazing! Great work!')\n",
    "print('MSE:',mean_squared_error(y, my_reg.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "O8SkLBtndUCa"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2MBQvCcbzEh"
   },
   "source": [
    "##Задание 5 (1 балл)\n",
    " Обучите линейную регрессию из коробки с l1-регуляризацией (from sklearn.linear_model import Lasso, первый и четвертый варианты) или с l2-регуляризацией (from sklearn.linear_model import Ridge, второй и третий варианты) с значением параметра регуляризации 0.1. Обучите вашу линейную регрессию с тем же значением параметра регуляризации и сравните результаты. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "5jFIupFebzEj"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "-xTZhXkguCFw",
    "outputId": "2b312aa9-2b7c-4fc7-f536-75e69e67ea56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE линейной регрессии из коробки с l1-регуляризацией:0.10130120734785844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.        ,  0.        , -0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        , 32.57713139,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        , -0.        , 82.58541362,  0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "       -0.        , -0.        ,  0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        , 55.93631958, 63.15834586, -0.        , -0.        ,\n",
       "        0.        ,  0.        , 90.07374492, -0.        ,  0.        ,\n",
       "       -0.        , -0.        , 20.46611002, 71.45590813,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        , 21.04876285, -0.        ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        , -0.        ,  0.        ,\n",
       "       -0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "        0.        , -0.        ,  0.        , -0.        , -0.        ,\n",
       "        0.        ,  0.        , -0.        , 40.11645013, -0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        , 84.80846613,\n",
       "        0.        ,  0.        , -0.        , -0.        ,  0.        ])"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regres = Lasso(0.1)\n",
    "regres.fit(X,y)\n",
    "print('MSE линейной регрессии из коробки с l1-регуляризацией:{}'.format(mean_squared_error(y,regres.predict(X))))\n",
    "regres.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "pSw5F96ZuUIH",
    "outputId": "9e7d8fe8-330c-474c-99c4-841ead811e48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.15234076e-02  4.41076068e-02  5.04206829e-02 -4.86130490e-02\n",
      "  4.47197910e-02  5.15542363e-02  5.68793653e-02 -6.00101357e-02\n",
      " -4.93116926e-02  5.13594553e-02  5.23071222e-02  3.26333591e+01\n",
      "  6.08867155e-02  4.71870947e-02  5.10841327e-02  6.09516675e-02\n",
      "  4.74930272e-02  5.43766833e-02 -4.85950160e-02  4.65012984e-02\n",
      " -4.09596431e-02  5.09527091e-02  5.27958015e-02  8.26169736e+01\n",
      "  5.50161879e-02  4.65593001e-02 -4.88220849e-02  4.68277217e-02\n",
      " -4.44100760e-02  4.63765083e-02 -5.46863435e-02  5.09466307e-02\n",
      " -4.15849132e-02  4.68703469e-02  5.66730063e-02  5.36803363e-02\n",
      " -4.73709887e-02 -4.59916474e-02 -5.65305753e-02  5.77505188e-02\n",
      "  5.20369841e-02  6.05322165e-02  4.96070071e-02  4.44578747e-02\n",
      " -6.03281310e-02 -5.29355773e-02  5.59789506e+01  6.31958350e+01\n",
      "  5.07723737e-02  4.91373744e-02 -4.56930065e-02 -4.61374328e-02\n",
      "  9.01096021e+01  4.05661683e-02 -3.56892376e-02  4.67426171e-02\n",
      "  5.11844072e-02  2.05148328e+01  7.14879609e+01 -5.21048464e-02\n",
      "  4.71802816e-02 -4.82161742e-02  4.75332889e-02 -5.29369551e-02\n",
      "  6.58425513e-02  4.87477618e-02  5.20894572e-02  2.10916725e+01\n",
      " -6.37451925e-02  6.31654078e-02 -4.98892033e-02  4.95948030e-02\n",
      " -4.49208375e-02 -5.70765335e-02  4.81976627e-02 -5.24301096e-02\n",
      " -4.53985320e-02 -5.29376792e-02 -4.82196048e-02 -5.00574733e-02\n",
      " -5.07021175e-02 -5.44090143e-02 -4.96813088e-02  4.68220176e-02\n",
      "  4.37026347e-02 -4.72164934e-02 -5.08685927e-02  5.01343944e-02\n",
      "  4.01509564e+01  6.08668251e-02 -5.46757697e-02 -4.96886356e-02\n",
      " -5.31172612e-02  5.03036885e-02  8.48425443e+01 -4.42277025e-02\n",
      "  5.69176947e-02  4.95300179e-02 -4.58422340e-02  5.25359567e-02\n",
      " -5.23656600e-02]\n",
      "MSE моей линейной регрессии с l1-регуляризацией:0.3010409505977648\n"
     ]
    }
   ],
   "source": [
    "regres_1 = LinearRegression_1(l_ratio=0.1)\n",
    "regres_1.fit(X,y)\n",
    "print('MSE моей линейной регрессии с l1-регуляризацией:{}'.format(mean_squared_error(y,regres_1.predict(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vi5u-WOAvBOt"
   },
   "source": [
    "Встроенная регрессия с регуляризацией имеет меньшую MSE и большинство параметров вектора w обнуляются, в моей модели те же параметры стрмятся к обнулению, однако не доходят до нуля, приобретая просто очень маленькие значения. Скорее всего, такие различия связаны со внутренним устройством алгоритмов, в моей модели используется классический градиентный спуск, а в Lasso метод покоординатного спуска."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "PphjvLz6bzDS",
    "4QcBYWvP23KV",
    "AmDgSUwf6Vtb",
    "X7iH1VaUrsEz",
    "s4vK_r-srni1",
    "t2MBQvCcbzEh"
   ],
   "name": "Homework2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
